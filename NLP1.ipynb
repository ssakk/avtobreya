{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cb3c93",
   "metadata": {},
   "source": [
    "Домашняя работа 1  \n",
    "Зенина Алёна БКЛ-201\n",
    "# 1) Сбор данных\n",
    "В качестве источника данных использован сайт [otziv-otziv.ru](otziv-otziv.ru), а точнее его раздел с отзывами на различные вина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6209d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c195a",
   "metadata": {},
   "source": [
    "Собираю все ссылки на страницу каждого вина с общей страницы каталога отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43488a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vine_page = [] \n",
    "\n",
    "for i in range(1, 107):\n",
    "    req = 'https://otziv-otziv.ru/katalog/vino/?page=' + str(i)\n",
    "    response = requests.get(req)\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        page = soup.findAll('div', {'class': 'content'})\n",
    "        \n",
    "        for block in page:\n",
    "            vine_page.append(block.find('a')['href'])\n",
    "            \n",
    "    else:\n",
    "        print(i, ' error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e9e005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vine_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1719d",
   "metadata": {},
   "source": [
    "Собираю положительные (оценка 4, 5) и отрицательные (оценка 1, 2) отзывы на вина  \n",
    "Не беру отзывы, где стоит оценка 3, потому что она по идее тонально не окрашена  \n",
    "*Warning! следующий кусок работает ооочень долго (около получаса)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8f816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_global = []\n",
    "neg_global= []\n",
    "\n",
    "for i in vine_page:\n",
    "    req = 'https://otziv-otziv.ru' + i\n",
    "    response = requests.get(req)\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        review = soup.findAll('div', {'class': 'container-reviews'})\n",
    "\n",
    "        for block in review:\n",
    "            rating = int(block.find('div', {'class': 'stars-container'}).get('title')[-1])    \n",
    "            text = block.get_text()[24:]\n",
    "    \n",
    "            if rating > 3:\n",
    "                pos_global.append(text)\n",
    "                \n",
    "            elif rating < 3:\n",
    "                neg_global.append(text)\n",
    "     \n",
    "    else:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1714d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Положительных отзывов:  4003 \n",
      "Отрицательных отзывов: 746\n"
     ]
    }
   ],
   "source": [
    "print('Положительных отзывов: ', len(pos_global), '\\nОтрицательных отзывов:', len(neg_global))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f655b47",
   "metadata": {},
   "source": [
    "# 2) Предпроцессинг\n",
    "Выборка по винам получилась несбалансированной, поэтому, пытаюсь ее уравновесить, выбирая из большего массива количество отзывов равное величине меньшего (в нашем случае положительных больше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d4e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06dfac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def here(posx, negx):\n",
    "\n",
    "    if len(posx) > len(negx):\n",
    "        a = random.choices(np.array(posx), k=min(len(posx), len(negx)))\n",
    "        b = negx\n",
    "    \n",
    "    elif len(posx) < len(negx):\n",
    "        a = posx\n",
    "        b = random.choices(np.array(negx), k=min(len(posx), len(negx)))\n",
    "    \n",
    "    else:\n",
    "        a = posx\n",
    "        b = negx\n",
    "        \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89753f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Положительных отзывов:  746 \n",
      "Отрицательных отзывов: 746\n"
     ]
    }
   ],
   "source": [
    "pos, neg = here(pos_global, neg_global)\n",
    "print('Положительных отзывов: ', len(pos), '\\nОтрицательных отзывов:', len(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0dc5f9",
   "metadata": {},
   "source": [
    "Итого общая выборка получается объемом 1492 отзыва, примерно одну десятую оставляю на проверку качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b3e3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "r = round(min(len(pos), len(neg))/10)\n",
    "\n",
    "if r%2 == 1:\n",
    "    r -= 1\n",
    "    \n",
    "for i in pos[0: r]:\n",
    "    sample.append(i)\n",
    "\n",
    "for i in neg[0: r]:\n",
    "    sample.append(i)\n",
    "    \n",
    "del neg[0: r]\n",
    "del pos[0: r] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8a19c",
   "metadata": {},
   "source": [
    "Делаю массив из 1 и -1, характеризующих тональность отзыва (1 = положительный, -1 = отрицательный), для дальнейшей проверки точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc912d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "for i in range(0, r):\n",
    "    y.append(1)\n",
    "\n",
    "for i in range(0, r):\n",
    "    y.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63cf93",
   "metadata": {},
   "source": [
    "Токенизирую слова, привожу к нижнему регистру и к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29499fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae5e284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(lst):\n",
    "    all_words = []\n",
    "    \n",
    "    for comment in lst:\n",
    "        tokens = nltk.word_tokenize(comment)\n",
    "        words = [word.lower() for word in tokens if word.isalpha()]\n",
    "        all_words.extend(lemmatize(words))\n",
    "    \n",
    "    return all_words\n",
    "\n",
    "def tokenize_string(strg):\n",
    "    tokens = nltk.word_tokenize(strg)\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "    lemmas = lemmatize(words)\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "def lemmatize(lst):\n",
    "    res = []\n",
    "    \n",
    "    for word in lst:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805e1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_neg = tokenize_list(neg)\n",
    "tokenized_pos = tokenize_list(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45832316",
   "metadata": {},
   "source": [
    "# 3) Составление словарей\n",
    "Создаю частотный словарь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ede08cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "861913a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_neg = Counter(tokenized_neg)\n",
    "counted_pos = Counter(tokenized_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4eca6",
   "metadata": {},
   "source": [
    "Ввожу функцию, которая убирает из частотного словаря слова, которые встретились меньше определенного количества раз и убирает значения частотности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91235905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequently(dct, n):\n",
    "    words = np.array([i for i in dct.keys()])\n",
    "    frequency = np.array([i for i in dct.values()])\n",
    "    res = set(words[frequency > n])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "504ef71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0  Количество слов в +:  1614  Количество слов в -:  1904\n",
      "i = 1  Количество слов в +:  785  Количество слов в -:  812\n",
      "i = 2  Количество слов в +:  508  Количество слов в -:  521\n",
      "i = 3  Количество слов в +:  395  Количество слов в -:  400\n",
      "i = 4  Количество слов в +:  327  Количество слов в -:  323\n",
      "i = 5  Количество слов в +:  269  Количество слов в -:  275\n",
      "i = 6  Количество слов в +:  230  Количество слов в -:  235\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,7):\n",
    "    print('i =', i, ' Количество слов в +: ', len(frequently(counted_pos, i)), ' Количество слов в -: ', len(frequently(counted_neg, i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbcefe",
   "metadata": {},
   "source": [
    "Далее буду рассматривать вариант, что частотность больше 2, но этот параметр можно поменять и возможно, получится другой конечный результат (об этом далее в разделе 5)  \n",
    "Убираю пересекающиеся в обоих словарях слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c129b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_neg = frequently(counted_neg, 2).difference(frequently(counted_pos, 2))\n",
    "unique_pos = frequently(counted_pos, 2).difference(frequently(counted_neg, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b5cab",
   "metadata": {},
   "source": [
    "# 4) Положительный или отрицательный?\n",
    "Ввожу функцию опредления тональности, которая выдает такую тональность, к словарю которой относится больше слов в выбранном отзыве  \n",
    "Если в функции слов из обоих словарей будет одинаково, то будем считать его положительным, поскольку их больше (опытным путем выяснено, что это улучшает результат на 20+%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d30168d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone(test, posx, negx):\n",
    "    y_pred = []\n",
    "    \n",
    "    for text in test:\n",
    "        val = 0\n",
    "        tokenized_text = tokenize_string(text)\n",
    "        \n",
    "        for token in tokenized_text:\n",
    "            \n",
    "            if token in posx:\n",
    "                val += 1\n",
    "            \n",
    "            if token in negx: \n",
    "                val -= 1\n",
    "        \n",
    "        if val >= 0: \n",
    "            y_pred.append(1)\n",
    "        \n",
    "        if val < 0:\n",
    "            y_pred.append(-1)\n",
    "        \n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca401bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c0eb09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837837837837838"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, tone(sample, unique_pos, unique_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e9da8",
   "metadata": {},
   "source": [
    "Неплохо! Но будем пытаться улучшать!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b8e94",
   "metadata": {},
   "source": [
    "# 5) Улучшения\n",
    "### 5.1) Окно\n",
    "**Первое**, что пришло в голову, это поменять допустимое окно частотности слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6477552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0  Accuracy  0.7567567567567568\n",
      "i = 1  Accuracy  0.7702702702702703\n",
      "i = 2  Accuracy  0.7837837837837838\n",
      "i = 3  Accuracy  0.7837837837837838\n",
      "i = 4  Accuracy  0.7635135135135135\n",
      "i = 5  Accuracy  0.75\n",
      "i = 6  Accuracy  0.722972972972973\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,7):\n",
    "    print('i =', i, ' Accuracy ', accuracy_score(y, tone(sample, frequently(counted_pos, i).difference(frequently(counted_neg, i)), frequently(counted_neg, i).difference(frequently(counted_pos, i)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a6bc0",
   "metadata": {},
   "source": [
    "Предположительно лучшее окно - 2 (так как при каждом новом запуске программы, тексты немного меняются, могу сказать, что окно два дает лучшие результаты)\n",
    "### 5.2) Стоп-слова\n",
    "**Второе**, убрать стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd80f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba9b59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a119ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Положительных со стоп-словами  211 без стоп-слов  205 \n",
      "Отрицательных со стоп-словами  224 без стоп-слов  210\n"
     ]
    }
   ],
   "source": [
    "stops_pos = unique_pos.difference(stops)\n",
    "stops_neg = unique_neg.difference(stops)\n",
    "print( 'Положительных со стоп-словами ', len(unique_pos), 'без стоп-слов ', len(stops_pos), '\\nОтрицательных со стоп-словами ', len(unique_neg), 'без стоп-слов ', len(stops_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d06c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0  Accuracy  0.7432432432432432\n",
      "i = 1  Accuracy  0.7702702702702703\n",
      "i = 2  Accuracy  0.7972972972972973\n",
      "i = 3  Accuracy  0.7635135135135135\n",
      "i = 4  Accuracy  0.75\n",
      "i = 5  Accuracy  0.722972972972973\n",
      "i = 6  Accuracy  0.722972972972973\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,7):\n",
    "    print('i =', i, ' Accuracy ', accuracy_score(y, tone(sample, frequently(counted_pos, i).difference(frequently(counted_neg, i)).difference(stops), frequently(counted_neg, i).difference(frequently(counted_pos, i)).difference(stops))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e96122",
   "metadata": {},
   "source": [
    "Непонятно, лучше или хуже в целом, так как конкретно в это случае со стоп-словами получилось лучше, а в предыдущий раз нет, но по идее в стоп-словах есть слова, обозначающие противопоставление и отрицание, которые важны для отрицательных отзывов \n",
    "### 5.3) Учитывать ранг слова (спойлер! не вышло ничего хорошего)\n",
    "**Третье**, попытаться присвоить значения ранга каждому слову в зависимости от частоты встречаемости: чем чаще, тем больше важности  \n",
    "Меняю функцию *frequently* на ее аналог, выдающий словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06f48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def often(dct, n):\n",
    "    new_dct = {}\n",
    "    words = np.array([i for i in dct.keys()])\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if dct[word] > n:\n",
    "            new_dct[word] = dct[word]\n",
    "\n",
    "    return new_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b676032",
   "metadata": {},
   "source": [
    "Так как теперь работа идет со словарями, очищать от пересекающейся лексики их придется отдельной функцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53c6cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(dct_pos, dct_neg):\n",
    "    new_pos = {}\n",
    "    new_neg = {}\n",
    "    words_pos = np.array([i for i in dct_pos.keys()])\n",
    "    words_neg = np.array([i for i in dct_neg.keys()])\n",
    "    \n",
    "    for word1 in words_pos:\n",
    "        \n",
    "        if word1 not in words_neg:\n",
    "            new_pos[word1] = dct_pos[word1]\n",
    "            \n",
    "    for word2 in words_neg:\n",
    "        \n",
    "        if word2 not in words_neg:\n",
    "            new_pos[word2] = dct_pos[word2]\n",
    "            \n",
    "    return new_pos, new_neg   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "137e2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_pos, some_neg = clear(counted_pos, counted_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff87c99",
   "metadata": {},
   "source": [
    "Я пыталась подобрать функцию, которая бы связывала частотность и вклад в тональность, но что-то в целом тут не так, поэтому что есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be01a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_upgrade(test, posx, negx):\n",
    "    y_pred = []\n",
    "    pos_words = np.array([i for i in posx.keys()])\n",
    "    neg_words = np.array([i for i in negx.keys()])\n",
    "    \n",
    "    for text in test:\n",
    "        val = 0\n",
    "        tokenized_text = tokenize_string(text)\n",
    "        \n",
    "        for token in tokenized_text:\n",
    "            \n",
    "            if token in pos_words:\n",
    "                val += 1.1**int(posx[token])\n",
    "            \n",
    "            if token in neg_words: \n",
    "                val -= 1.1**int(negx[token])\n",
    "        \n",
    "        if val >= 0: \n",
    "            y_pred.append(1)\n",
    "        \n",
    "        if val < 0:\n",
    "            y_pred.append(-1)\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34968271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-3917d4d5ed91>:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if token in neg_words:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 2  Accuracy  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-3917d4d5ed91>:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if token in neg_words:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 3  Accuracy  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-3917d4d5ed91>:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if token in neg_words:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 4  Accuracy  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-3917d4d5ed91>:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if token in neg_words:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 5  Accuracy  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-3917d4d5ed91>:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if token in neg_words:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 6  Accuracy  0.5\n"
     ]
    }
   ],
   "source": [
    "for i in range (2,7):\n",
    "    print('i =', i, ' Accuracy ', accuracy_score(y, tone_upgrade(sample, often(some_pos, i), often(some_neg, i))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c76302",
   "metadata": {},
   "source": [
    "Все сломалось(( со словарями сложно  \n",
    "В итоге самая лучшая точность получилась просто подбром окна с исключением стоп-слов (0.7972972972972973), в предыдущей итерации  без (0.7905405405405406)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
